{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Genre Labelling Model\n",
    "\n",
    "Hello! I am Daniel Lim, and this is a notebook outlining the end-to-end project I have\n",
    "done to train a Music Genre Labelling Model. The dataset used is the [million song\n",
    "dataset](http://millionsongdataset.com/) (T. Bertin-Mahieux, D. P.W. Ellis, B. Whitman, and P. Lamere.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Setup: Imports + Reading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import nltk\n",
    "import os\n",
    "import re\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inputs = pd.read_csv('data/features.csv')\n",
    "df_labels = pd.read_csv('data/labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Details About This Project:\n",
    "\n",
    "In this project, the task is to develop and serve a classification model for musical\n",
    "genres. The data provided has been split into **features** and **labels**, which are in\n",
    "their own `.csv` files.\n",
    "\n",
    "The task can be split into the following parts:\n",
    "1. Exploratory Data Analysis (EDA) On the Dataset\n",
    "2. Data Processing for Training\n",
    "3. Choosing & Training a Model\n",
    "4. Serving the Model to a Web Service\n",
    "\n",
    "Most of the actual implementation of this project will be in `.py` scripts, but for\n",
    "exploration and preliminary tests, I will be using this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: EDA On the Dataset\n",
    "\n",
    "The beginning of any Machine Learning / Data Science / AI project should include an\n",
    "understanding of the dataset before any solutions are applied. This should aid the steps\n",
    "downstream as well, as an understanding of the data would guide decisions in **data preprocessing** and **model training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Schema:\n",
    "\n",
    "Pasting the Dataset Schema provided in the `README` file below:\n",
    "\n",
    "========\n",
    "Features\n",
    "========\n",
    "\n",
    "* trackID: unique identifier for each song (Maps features to their labels)\n",
    "* title: title of the song. Type: text.\n",
    "* tags: A comma-separated list of tags representing the words that appeared in the lyrics of the song and are assigned by human annotators. Type: text / categorical.\n",
    "* loudness: overall loudness in dB. Type: float / continuous.\n",
    "* tempo: estimated tempo in beats per minute (BPM). Type: float / continuous.\n",
    "* time_signature: estimated number of beats per bar. Type: integer.\n",
    "* key: key the track is in. Type: integer/ nominal. \n",
    "* mode: major or minor. Type: integer / binary.\n",
    "* duration: duration of the song in seconds. Type: float / continuous.\n",
    "* vect_1 ... vect_148: 148 columns containing pre-computed audio features of each song. \n",
    "\t- These features were pre-extracted (NO TEMPORAL MEANING) from the 30 or 60 second snippets, and capture timbre, chroma, and mfcc aspects of the audio. \\\n",
    "\t- Each feature takes a continuous value. Type: float / continuous.\n",
    " \n",
    "\n",
    "=======\n",
    "Labels\n",
    "=======\n",
    "\n",
    "* trackID: unique id for each song (Maps features to their labels)\n",
    "* genre: the genre label\n",
    "\t1. Soul and Reggae\n",
    "\t2. Pop\n",
    "\t3. Punk\n",
    "\t4. Jazz and Blues\n",
    "\t5. Dance and Electronica\n",
    "\t6. Folk\n",
    "\t7. Classic Pop and Rock\n",
    "\t8. Metal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These details are very helpful, as it helps us to understand the features that we are\n",
    "working with, especially in terms of data types, and how each feature might relate to\n",
    "the label.\n",
    "\n",
    "Here's a quick runthrough of the features and some early impressions:\n",
    "\n",
    "* `trackID`: Mainly to join the features to their labels, no meaning to the label\n",
    "* `title`: Might potentially relate to the label, maybe more aggressive names might mean\n",
    "  a more \"aggressive\" genre?\n",
    "* `tags`: Lyrics might definitely relate to the genre\n",
    "* `loudness`, `tempo`, `time_signature`... `duration`: The rest of the features could\n",
    "  be related to the genres as well\n",
    "* `vect_1` to `vect_148`: These are pre-extracted features, and from the description,\n",
    "  they seem to provide a lot of finer details in the songs. It's also good to know that\n",
    "  they don't have any temporal meaning, as that would have other implications, such as\n",
    "  choosing a model that can handle sequential data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1a. Quick observation of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackID</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>duration</th>\n",
       "      <th>vect_1</th>\n",
       "      <th>...</th>\n",
       "      <th>vect_139</th>\n",
       "      <th>vect_140</th>\n",
       "      <th>vect_141</th>\n",
       "      <th>vect_142</th>\n",
       "      <th>vect_143</th>\n",
       "      <th>vect_144</th>\n",
       "      <th>vect_145</th>\n",
       "      <th>vect_146</th>\n",
       "      <th>vect_147</th>\n",
       "      <th>vect_148</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6654</td>\n",
       "      <td>Beside the Yellow Line</td>\n",
       "      <td>i, the, to, and, a, me, it, not, in, my, is, o...</td>\n",
       "      <td>-8.539</td>\n",
       "      <td>104.341</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>298.73587</td>\n",
       "      <td>44.462048</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000308</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.130826</td>\n",
       "      <td>1.071914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5883</td>\n",
       "      <td>Ooh Na Na</td>\n",
       "      <td>i, you, to, and, a, me, it, not, in, my, is, y...</td>\n",
       "      <td>-4.326</td>\n",
       "      <td>141.969</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>236.09424</td>\n",
       "      <td>46.069761</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001751</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.001920</td>\n",
       "      <td>0.001950</td>\n",
       "      <td>0.001937</td>\n",
       "      <td>0.001912</td>\n",
       "      <td>0.001836</td>\n",
       "      <td>0.001740</td>\n",
       "      <td>0.148765</td>\n",
       "      <td>0.882304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3424</td>\n",
       "      <td>Calabria 2008</td>\n",
       "      <td>i, the, you, to, and, a, me, it, not, in, of, ...</td>\n",
       "      <td>-9.637</td>\n",
       "      <td>126.003</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>412.94322</td>\n",
       "      <td>40.376622</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000951</td>\n",
       "      <td>0.001039</td>\n",
       "      <td>0.001116</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>0.001159</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.116206</td>\n",
       "      <td>0.306846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5434</td>\n",
       "      <td>Verbal Abuse (Just an American Band)</td>\n",
       "      <td>i, you, to, and, a, me, it, not, my, is, your,...</td>\n",
       "      <td>-10.969</td>\n",
       "      <td>197.625</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.78322</td>\n",
       "      <td>45.598532</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.163738</td>\n",
       "      <td>1.247803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>516</td>\n",
       "      <td>Helen Of Troy</td>\n",
       "      <td>i, the, to, a, me, it, not, in, is, your, we, ...</td>\n",
       "      <td>-5.369</td>\n",
       "      <td>170.008</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.97342</td>\n",
       "      <td>47.159148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000853</td>\n",
       "      <td>0.000927</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>0.001037</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.001011</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.108193</td>\n",
       "      <td>0.366419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trackID                                 title  \\\n",
       "0     6654                Beside the Yellow Line   \n",
       "1     5883                             Ooh Na Na   \n",
       "2     3424                         Calabria 2008   \n",
       "3     5434  Verbal Abuse (Just an American Band)   \n",
       "4      516                         Helen Of Troy   \n",
       "\n",
       "                                                tags  loudness    tempo  \\\n",
       "0  i, the, to, and, a, me, it, not, in, my, is, o...    -8.539  104.341   \n",
       "1  i, you, to, and, a, me, it, not, in, my, is, y...    -4.326  141.969   \n",
       "2  i, the, you, to, and, a, me, it, not, in, of, ...    -9.637  126.003   \n",
       "3  i, you, to, and, a, me, it, not, my, is, your,...   -10.969  197.625   \n",
       "4  i, the, to, a, me, it, not, in, is, your, we, ...    -5.369  170.008   \n",
       "\n",
       "   time_signature   key  mode   duration     vect_1  ...  vect_139  vect_140  \\\n",
       "0             3.0   7.0   1.0  298.73587  44.462048  ...  0.000308  0.000302   \n",
       "1             3.0   6.0   0.0  236.09424  46.069761  ...  0.001751  0.001855   \n",
       "2             4.0  10.0   0.0  412.94322  40.376622  ...  0.000951  0.001039   \n",
       "3             4.0   2.0   1.0   64.78322  45.598532  ...  0.000233  0.000284   \n",
       "4             4.0   0.0   1.0  191.97342  47.159148  ...  0.000853  0.000927   \n",
       "\n",
       "   vect_141  vect_142  vect_143  vect_144  vect_145  vect_146  vect_147  \\\n",
       "0  0.000302  0.000315  0.000297  0.000305  0.000266  0.000225  0.130826   \n",
       "1  0.001920  0.001950  0.001937  0.001912  0.001836  0.001740  0.148765   \n",
       "2  0.001116  0.001166  0.001159  0.001110  0.001015  0.000895  0.116206   \n",
       "3  0.000313  0.000325  0.000324  0.000299  0.000273  0.000236  0.163738   \n",
       "4  0.000994  0.001037  0.001051  0.001011  0.000962  0.000898  0.108193   \n",
       "\n",
       "   vect_148  \n",
       "0  1.071914  \n",
       "1  0.882304  \n",
       "2  0.306846  \n",
       "3  1.247803  \n",
       "4  0.366419  \n",
       "\n",
       "[5 rows x 157 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackID</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8424</td>\n",
       "      <td>metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7923</td>\n",
       "      <td>folk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2314</td>\n",
       "      <td>folk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>810</td>\n",
       "      <td>jazz and blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>439</td>\n",
       "      <td>folk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trackID           genre\n",
       "0     8424           metal\n",
       "1     7923            folk\n",
       "2     2314            folk\n",
       "3      810  jazz and blues\n",
       "4      439            folk"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before any EDA, check the total number of entries and if there are any duplicates or missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8128"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! No duplicates. Now for missing values in each column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key         15\n",
      "vect_12     13\n",
      "vect_4      12\n",
      "vect_6      12\n",
      "tags        12\n",
      "            ..\n",
      "vect_84      1\n",
      "vect_118     1\n",
      "vect_120     1\n",
      "vect_121     1\n",
      "vect_73      1\n",
      "Length: 115, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values = df_inputs.isnull().sum()\n",
    "missing_columns = missing_values[missing_values > 0].sort_values(ascending=False)\n",
    "print(missing_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The good thing is there isn't any one column that has many rows missing values. Now I'll\n",
    "check how many rows will be dropped if I drop all rows with missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with missing values: 404\n"
     ]
    }
   ],
   "source": [
    "rows_with_missing_values = df_inputs.isnull().any(axis=1)\n",
    "print(f'Number of rows with missing values: {rows_with_missing_values.sum()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping all 404 of the rows would give us 7724 rows, which is still a decent amount,\n",
    "even though we are losing around 5% of the rows. The tradeoff of perfoming imputation\n",
    "like mean, median or even KNN imputation and potentially introducing noise / biases into\n",
    "the dataset is not worth it in my opinion, given the amount of rows we can still work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7724"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs = df_inputs.dropna()\n",
    "len(df_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the number of columns we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns: 157\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of columns: {df_inputs.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "157 is quite a lot of columns, and excluding the trackID, we still have 156 so the\n",
    "dimensionality of our problem might be quite high. This is before we even do a\n",
    "one-hot-encoding on the `key` column which I was intending to. We'll have to keep the\n",
    "dimensionality in mind as we move along."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, looking at some descriptive statisitics about the inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackID</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>duration</th>\n",
       "      <th>vect_1</th>\n",
       "      <th>vect_2</th>\n",
       "      <th>vect_3</th>\n",
       "      <th>...</th>\n",
       "      <th>vect_139</th>\n",
       "      <th>vect_140</th>\n",
       "      <th>vect_141</th>\n",
       "      <th>vect_142</th>\n",
       "      <th>vect_143</th>\n",
       "      <th>vect_144</th>\n",
       "      <th>vect_145</th>\n",
       "      <th>vect_146</th>\n",
       "      <th>vect_147</th>\n",
       "      <th>vect_148</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "      <td>7724.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4275.560979</td>\n",
       "      <td>-9.533505</td>\n",
       "      <td>125.778853</td>\n",
       "      <td>3.576644</td>\n",
       "      <td>5.240031</td>\n",
       "      <td>0.685785</td>\n",
       "      <td>238.656432</td>\n",
       "      <td>43.675231</td>\n",
       "      <td>3.802539</td>\n",
       "      <td>8.809924</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000715</td>\n",
       "      <td>0.000763</td>\n",
       "      <td>0.000789</td>\n",
       "      <td>0.000813</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>0.000743</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>0.194231</td>\n",
       "      <td>5.254273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2480.518111</td>\n",
       "      <td>4.390825</td>\n",
       "      <td>34.716748</td>\n",
       "      <td>1.194295</td>\n",
       "      <td>3.594905</td>\n",
       "      <td>0.464233</td>\n",
       "      <td>88.938726</td>\n",
       "      <td>5.647718</td>\n",
       "      <td>48.420691</td>\n",
       "      <td>29.641771</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>0.000711</td>\n",
       "      <td>0.000719</td>\n",
       "      <td>0.000714</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.000682</td>\n",
       "      <td>0.000645</td>\n",
       "      <td>0.086668</td>\n",
       "      <td>42.457995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-35.726000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.276280</td>\n",
       "      <td>17.606993</td>\n",
       "      <td>-289.862566</td>\n",
       "      <td>-140.558193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2113.750000</td>\n",
       "      <td>-12.205250</td>\n",
       "      <td>99.885250</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>186.330980</td>\n",
       "      <td>40.038735</td>\n",
       "      <td>-26.435137</td>\n",
       "      <td>-8.403524</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.129483</td>\n",
       "      <td>0.730204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4278.500000</td>\n",
       "      <td>-8.755000</td>\n",
       "      <td>121.789500</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>227.826485</td>\n",
       "      <td>44.159327</td>\n",
       "      <td>8.532998</td>\n",
       "      <td>10.074590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.000609</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.000630</td>\n",
       "      <td>0.000596</td>\n",
       "      <td>0.000566</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.179960</td>\n",
       "      <td>1.590191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6422.250000</td>\n",
       "      <td>-6.122000</td>\n",
       "      <td>147.018000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>275.415060</td>\n",
       "      <td>48.004400</td>\n",
       "      <td>38.050538</td>\n",
       "      <td>27.163832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>0.001019</td>\n",
       "      <td>0.001051</td>\n",
       "      <td>0.001050</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.245426</td>\n",
       "      <td>3.756182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8555.000000</td>\n",
       "      <td>-0.414000</td>\n",
       "      <td>253.036000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1271.718730</td>\n",
       "      <td>55.564543</td>\n",
       "      <td>150.885303</td>\n",
       "      <td>157.483210</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006545</td>\n",
       "      <td>0.006613</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.006682</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>0.006777</td>\n",
       "      <td>0.006770</td>\n",
       "      <td>0.006632</td>\n",
       "      <td>0.767182</td>\n",
       "      <td>3193.622527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 155 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           trackID     loudness        tempo  time_signature          key  \\\n",
       "count  7724.000000  7724.000000  7724.000000     7724.000000  7724.000000   \n",
       "mean   4275.560979    -9.533505   125.778853        3.576644     5.240031   \n",
       "std    2480.518111     4.390825    34.716748        1.194295     3.594905   \n",
       "min       0.000000   -35.726000     0.000000        0.000000     0.000000   \n",
       "25%    2113.750000   -12.205250    99.885250        3.000000     2.000000   \n",
       "50%    4278.500000    -8.755000   121.789500        4.000000     5.000000   \n",
       "75%    6422.250000    -6.122000   147.018000        4.000000     9.000000   \n",
       "max    8555.000000    -0.414000   253.036000        7.000000    11.000000   \n",
       "\n",
       "              mode     duration       vect_1       vect_2       vect_3  ...  \\\n",
       "count  7724.000000  7724.000000  7724.000000  7724.000000  7724.000000  ...   \n",
       "mean      0.685785   238.656432    43.675231     3.802539     8.809924  ...   \n",
       "std       0.464233    88.938726     5.647718    48.420691    29.641771  ...   \n",
       "min       0.000000     5.276280    17.606993  -289.862566  -140.558193  ...   \n",
       "25%       0.000000   186.330980    40.038735   -26.435137    -8.403524  ...   \n",
       "50%       1.000000   227.826485    44.159327     8.532998    10.074590  ...   \n",
       "75%       1.000000   275.415060    48.004400    38.050538    27.163832  ...   \n",
       "max       1.000000  1271.718730    55.564543   150.885303   157.483210  ...   \n",
       "\n",
       "          vect_139     vect_140     vect_141     vect_142     vect_143  \\\n",
       "count  7724.000000  7724.000000  7724.000000  7724.000000  7724.000000   \n",
       "mean      0.000715     0.000763     0.000789     0.000813     0.000809   \n",
       "std       0.000649     0.000684     0.000711     0.000719     0.000714   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000278     0.000298     0.000304     0.000319     0.000317   \n",
       "50%       0.000556     0.000592     0.000609     0.000632     0.000630   \n",
       "75%       0.000915     0.000983     0.001019     0.001051     0.001050   \n",
       "max       0.006545     0.006613     0.006698     0.006682     0.006645   \n",
       "\n",
       "          vect_144     vect_145     vect_146     vect_147     vect_148  \n",
       "count  7724.000000  7724.000000  7724.000000  7724.000000  7724.000000  \n",
       "mean      0.000778     0.000743     0.000694     0.194231     5.254273  \n",
       "std       0.000707     0.000682     0.000645     0.086668    42.457995  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000299     0.000292     0.000273     0.129483     0.730204  \n",
       "50%       0.000596     0.000566     0.000528     0.179960     1.590191  \n",
       "75%       0.000998     0.000943     0.000869     0.245426     3.756182  \n",
       "max       0.006777     0.006770     0.006632     0.767182  3193.622527  \n",
       "\n",
       "[8 rows x 155 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some findings from the descriptive statistics:\n",
    "\n",
    "A simple observation is that the values are not normalised, and the range of the values\n",
    "can be quite wide as well as their distribution, like in `vect_2`, where the minimum is\n",
    "-289.9, but the mean is only 3.8, and the max is 150.9. We'll definitely have to scale\n",
    "the data if we are working with a deep learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1a. Findings:\n",
    "\n",
    "Some important findings from this part are:\n",
    "1. No duplicates in data\n",
    "2. 404 rows with missing values\n",
    "3. Total of 157 columns before data preprocessing\n",
    "4. Vectors are not normalised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1b. Deeper Dive Into EDA\n",
    "\n",
    "This section will aim to get more insights on specific columns to decide the best course\n",
    "of action for the data preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before looking at the inputs, we should find out the distribution of the genres "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genres: 8\n",
      "Value Counts: genre\n",
      "classic pop and rock     1684\n",
      "folk                     1665\n",
      "metal                    1209\n",
      "soul and reggae           988\n",
      "punk                      981\n",
      "pop                       731\n",
      "dance and electronica     523\n",
      "jazz and blues            347\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of genres: {len(df_labels[\"genre\"].value_counts())}')\n",
    "\n",
    "print(f\"Value Counts: {df_labels['genre'].value_counts()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright, we have 8 classes, and an imbalanced amount of samples for each class. We can\n",
    "address this by doing a stratified train test split when it comes to it. Next, let's\n",
    "look at the input data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's start off by looking at the `tags` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `tags` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackID</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6654</td>\n",
       "      <td>i, the, to, and, a, me, it, not, in, my, is, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3424</td>\n",
       "      <td>i, the, you, to, and, a, me, it, not, in, of, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5434</td>\n",
       "      <td>i, you, to, and, a, me, it, not, my, is, your,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>516</td>\n",
       "      <td>i, the, to, a, me, it, not, in, is, your, we, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4906</td>\n",
       "      <td>i, the, you, to, and, a, me, it, not, in, is, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8123</th>\n",
       "      <td>1802</td>\n",
       "      <td>i, the, you, to, and, a, me, it, not, in, is, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8124</th>\n",
       "      <td>3397</td>\n",
       "      <td>i, the, you, to, and, a, me, it, not, in, my, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8125</th>\n",
       "      <td>1760</td>\n",
       "      <td>i, the, you, me, it, not, in, my, is, your, do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8126</th>\n",
       "      <td>2114</td>\n",
       "      <td>i, the, you, and, it, in, my, is, of, your, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8127</th>\n",
       "      <td>2252</td>\n",
       "      <td>i, you, to, and, a, me, not, in, is, do, are, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7724 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      trackID                                               tags\n",
       "0        6654  i, the, to, and, a, me, it, not, in, my, is, o...\n",
       "2        3424  i, the, you, to, and, a, me, it, not, in, of, ...\n",
       "3        5434  i, you, to, and, a, me, it, not, my, is, your,...\n",
       "4         516  i, the, to, a, me, it, not, in, is, your, we, ...\n",
       "5        4906  i, the, you, to, and, a, me, it, not, in, is, ...\n",
       "...       ...                                                ...\n",
       "8123     1802  i, the, you, to, and, a, me, it, not, in, is, ...\n",
       "8124     3397  i, the, you, to, and, a, me, it, not, in, my, ...\n",
       "8125     1760  i, the, you, me, it, not, in, my, is, your, do...\n",
       "8126     2114  i, the, you, and, it, in, my, is, of, your, th...\n",
       "8127     2252  i, you, to, and, a, me, not, in, is, do, are, ...\n",
       "\n",
       "[7724 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs[['trackID','tags']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right off the bat, it looks like the tags contain many **stop words** (words commonly used\n",
    "in a language that have little value for tasks like text classification). Before\n",
    "carrying on, I'll remove them so I can make a better analysis on the `tags` column.\n",
    "\n",
    "To do this, I'll utilise the Natural Language Toolkit library `nltk`, which has a list of\n",
    "common English stop words, to identify the stop words and remove them. Take note that\n",
    "the values are comma separated, and we can leverage that to accurately check each\n",
    "individual word.\n",
    "\n",
    "I'll define a function `remove_stop_words()` that takes in the string, splits them by\n",
    "commas and removes the stop words, and rejoins them with commas in between each word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/danny/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk.corpus.stopwords.words('english'))\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    words = text.split(',')\n",
    "    filtered_words = [word.strip() for word in words if word.strip().lower() not in stop_words]\n",
    "    return \", \".join(filtered_words)\n",
    "\n",
    "\n",
    "df_inputs[\"tags\"] = df_inputs[\"tags\"].apply(remove_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the stop words are removed, we can take a look at the remaining words to see\n",
    "what we're working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'know, time, way, take, yeah, back, heart, caus, man, mind, wo, still, long, girl, hand, call, leav, face, gone, alon, chang, god, stand, friend, hard, gotta, star, year, fear, black, line, onc, came, understand, goe, road, land, voic, guess, meet, bout, doubt, track, glad, ago, five, path, besid, float, yellow, unknown, except, pierc, railroad'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs['tags'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just looking at the first entry in the dataframe, we can see that the words have been\n",
    "stemmed, (\"cause\" has been changed to \"caus\", \"alone\" or \"along\" to \"alon\").\n",
    "\n",
    "Stemming is a form of text preprocessing that simplifies the vocabulary of the input\n",
    "text by dropping suffixes. However, this comes with the risk that some words might be\n",
    "stemmed incorrectly, reducing the information from the text. A good example would be\n",
    "how I mentioned before that \"alon\" could be either \"alone\" or \"along\", which have two\n",
    "very different meanings, but because it was already stemmed, we can't say for sure.\n",
    "\n",
    "An alternative to stemming would be lemmatisation, which takes into account the context\n",
    "of the word and uses a dictionary to reduce words to their base forms, instead of just\n",
    "cutting the suffixes out. However, this is more computationally expensive.\n",
    "\n",
    "Since our text is already stemmed, I'll leave it as it is.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Text Preprocessing Approach:\n",
    "\n",
    "Given that we have text data in our `tags` column, and that this text is meant to\n",
    "represent the lyrics that appeared in the song, the context of the text is quite\n",
    "important. To capture the semantics of the text better, I am going to opt to use word\n",
    "embeddings to preprocess the text data to be fed into the model over something like\n",
    "TF-IDF (Term Frequency - Inverse Document Frequency).\n",
    "\n",
    "Using this approach will also aid in lowering dimensionality of the text data, which\n",
    "would be a great benefit.\n",
    "\n",
    "Note that we will also have to perform a similar preprocessing for the `title` column as well.\n",
    "\n",
    "This will be implemented in a data preprocessing script. For now, let's move on to the\n",
    "`time_signature` column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `time_signature`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature is described as `estimated number of beats per bar`, which would imply\n",
    "discrete values. Let's confirm that by checking the value counts in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time_signature\n",
       "4.0    5152\n",
       "1.0    1052\n",
       "3.0     976\n",
       "5.0     371\n",
       "7.0     169\n",
       "0.0       4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs[\"time_signature\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, we have songs with 0 beats in a bar, strange. But music, being a creative\n",
    "output, doesn't necessarily follow any rules. \n",
    "\n",
    "One thing to note is that we have 6 categories of time signatures, and they are\n",
    "contained in 1 column. Since this isn't an Ordinal Feature where a higher number or a\n",
    "lower number necessarily means its better or worse, we should convert this feature into\n",
    "a one-hot-encoded feature to avoid letting the eventual model learn an incorrect\n",
    "relationship between `time_signature` and the genre. We can achieve this by simply\n",
    "running a `pd.get_dummies()` on the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackID</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>key</th>\n",
       "      <th>mode</th>\n",
       "      <th>duration</th>\n",
       "      <th>vect_1</th>\n",
       "      <th>vect_2</th>\n",
       "      <th>...</th>\n",
       "      <th>vect_145</th>\n",
       "      <th>vect_146</th>\n",
       "      <th>vect_147</th>\n",
       "      <th>vect_148</th>\n",
       "      <th>time_signature_0.0</th>\n",
       "      <th>time_signature_1.0</th>\n",
       "      <th>time_signature_3.0</th>\n",
       "      <th>time_signature_4.0</th>\n",
       "      <th>time_signature_5.0</th>\n",
       "      <th>time_signature_7.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6654</td>\n",
       "      <td>Beside the Yellow Line</td>\n",
       "      <td>know, time, way, take, yeah, back, heart, caus...</td>\n",
       "      <td>-8.539</td>\n",
       "      <td>104.341</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>298.73587</td>\n",
       "      <td>44.462048</td>\n",
       "      <td>-13.499814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.130826</td>\n",
       "      <td>1.071914</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3424</td>\n",
       "      <td>Calabria 2008</td>\n",
       "      <td>know, like, come, go, one, never, make, say, n...</td>\n",
       "      <td>-9.637</td>\n",
       "      <td>126.003</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>412.94322</td>\n",
       "      <td>40.376622</td>\n",
       "      <td>27.546188</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.000895</td>\n",
       "      <td>0.116206</td>\n",
       "      <td>0.306846</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5434</td>\n",
       "      <td>Verbal Abuse (Just an American Band)</td>\n",
       "      <td>time, come, go, one, see, want, day, away, nee...</td>\n",
       "      <td>-10.969</td>\n",
       "      <td>197.625</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.78322</td>\n",
       "      <td>45.598532</td>\n",
       "      <td>10.249509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.163738</td>\n",
       "      <td>1.247803</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>516</td>\n",
       "      <td>Helen Of Troy</td>\n",
       "      <td>go, see, back, wo, face, end, place, far, onc,...</td>\n",
       "      <td>-5.369</td>\n",
       "      <td>170.008</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.97342</td>\n",
       "      <td>47.159148</td>\n",
       "      <td>-52.070941</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.000898</td>\n",
       "      <td>0.108193</td>\n",
       "      <td>0.366419</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4906</td>\n",
       "      <td>Only Him Or Me - Original</td>\n",
       "      <td>know, like, time, come, go, see, got, never, f...</td>\n",
       "      <td>-16.516</td>\n",
       "      <td>142.254</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>146.75546</td>\n",
       "      <td>36.712606</td>\n",
       "      <td>-1.896533</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.131246</td>\n",
       "      <td>0.693531</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 162 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trackID                                 title  \\\n",
       "0     6654                Beside the Yellow Line   \n",
       "2     3424                         Calabria 2008   \n",
       "3     5434  Verbal Abuse (Just an American Band)   \n",
       "4      516                         Helen Of Troy   \n",
       "5     4906             Only Him Or Me - Original   \n",
       "\n",
       "                                                tags  loudness    tempo   key  \\\n",
       "0  know, time, way, take, yeah, back, heart, caus...    -8.539  104.341   7.0   \n",
       "2  know, like, come, go, one, never, make, say, n...    -9.637  126.003  10.0   \n",
       "3  time, come, go, one, see, want, day, away, nee...   -10.969  197.625   2.0   \n",
       "4  go, see, back, wo, face, end, place, far, onc,...    -5.369  170.008   0.0   \n",
       "5  know, like, time, come, go, see, got, never, f...   -16.516  142.254   4.0   \n",
       "\n",
       "   mode   duration     vect_1     vect_2  ...  vect_145  vect_146  vect_147  \\\n",
       "0   1.0  298.73587  44.462048 -13.499814  ...  0.000266  0.000225  0.130826   \n",
       "2   0.0  412.94322  40.376622  27.546188  ...  0.001015  0.000895  0.116206   \n",
       "3   1.0   64.78322  45.598532  10.249509  ...  0.000273  0.000236  0.163738   \n",
       "4   1.0  191.97342  47.159148 -52.070941  ...  0.000962  0.000898  0.108193   \n",
       "5   1.0  146.75546  36.712606  -1.896533  ...  0.000107  0.000114  0.131246   \n",
       "\n",
       "   vect_148  time_signature_0.0  time_signature_1.0  time_signature_3.0  \\\n",
       "0  1.071914               False               False                True   \n",
       "2  0.306846               False               False               False   \n",
       "3  1.247803               False               False               False   \n",
       "4  0.366419               False               False               False   \n",
       "5  0.693531               False               False               False   \n",
       "\n",
       "   time_signature_4.0  time_signature_5.0  time_signature_7.0  \n",
       "0               False               False               False  \n",
       "2                True               False               False  \n",
       "3                True               False               False  \n",
       "4                True               False               False  \n",
       "5               False                True               False  \n",
       "\n",
       "[5 rows x 162 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs = pd.get_dummies(df_inputs, columns=['time_signature'], prefix='time_signature')\n",
    "df_inputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `key`\n",
    "\n",
    "This feature is pretty similar in nature as `time_signature`, as it seems to be\n",
    "nominally encoded in a single column. Let's confirm this by checking the value counts again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "key\n",
       "0.0     1008\n",
       "7.0      934\n",
       "2.0      913\n",
       "9.0      908\n",
       "4.0      667\n",
       "11.0     602\n",
       "1.0      589\n",
       "5.0      547\n",
       "10.0     470\n",
       "6.0      442\n",
       "8.0      408\n",
       "3.0      236\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs[\"key\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surely enough, it was similarly encoded. We can simply run a `pd.get_dummies()` as well\n",
    "to convert this feature into a one hot encoded one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trackID</th>\n",
       "      <th>title</th>\n",
       "      <th>tags</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>mode</th>\n",
       "      <th>duration</th>\n",
       "      <th>vect_1</th>\n",
       "      <th>vect_2</th>\n",
       "      <th>vect_3</th>\n",
       "      <th>...</th>\n",
       "      <th>key_2.0</th>\n",
       "      <th>key_3.0</th>\n",
       "      <th>key_4.0</th>\n",
       "      <th>key_5.0</th>\n",
       "      <th>key_6.0</th>\n",
       "      <th>key_7.0</th>\n",
       "      <th>key_8.0</th>\n",
       "      <th>key_9.0</th>\n",
       "      <th>key_10.0</th>\n",
       "      <th>key_11.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6654</td>\n",
       "      <td>Beside the Yellow Line</td>\n",
       "      <td>know, time, way, take, yeah, back, heart, caus...</td>\n",
       "      <td>-8.539</td>\n",
       "      <td>104.341</td>\n",
       "      <td>1.0</td>\n",
       "      <td>298.73587</td>\n",
       "      <td>44.462048</td>\n",
       "      <td>-13.499814</td>\n",
       "      <td>26.257028</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3424</td>\n",
       "      <td>Calabria 2008</td>\n",
       "      <td>know, like, come, go, one, never, make, say, n...</td>\n",
       "      <td>-9.637</td>\n",
       "      <td>126.003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>412.94322</td>\n",
       "      <td>40.376622</td>\n",
       "      <td>27.546188</td>\n",
       "      <td>-24.231226</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5434</td>\n",
       "      <td>Verbal Abuse (Just an American Band)</td>\n",
       "      <td>time, come, go, one, see, want, day, away, nee...</td>\n",
       "      <td>-10.969</td>\n",
       "      <td>197.625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.78322</td>\n",
       "      <td>45.598532</td>\n",
       "      <td>10.249509</td>\n",
       "      <td>52.666606</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>516</td>\n",
       "      <td>Helen Of Troy</td>\n",
       "      <td>go, see, back, wo, face, end, place, far, onc,...</td>\n",
       "      <td>-5.369</td>\n",
       "      <td>170.008</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191.97342</td>\n",
       "      <td>47.159148</td>\n",
       "      <td>-52.070941</td>\n",
       "      <td>18.232822</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4906</td>\n",
       "      <td>Only Him Or Me - Original</td>\n",
       "      <td>know, like, time, come, go, see, got, never, f...</td>\n",
       "      <td>-16.516</td>\n",
       "      <td>142.254</td>\n",
       "      <td>1.0</td>\n",
       "      <td>146.75546</td>\n",
       "      <td>36.712606</td>\n",
       "      <td>-1.896533</td>\n",
       "      <td>3.454569</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 173 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   trackID                                 title  \\\n",
       "0     6654                Beside the Yellow Line   \n",
       "2     3424                         Calabria 2008   \n",
       "3     5434  Verbal Abuse (Just an American Band)   \n",
       "4      516                         Helen Of Troy   \n",
       "5     4906             Only Him Or Me - Original   \n",
       "\n",
       "                                                tags  loudness    tempo  mode  \\\n",
       "0  know, time, way, take, yeah, back, heart, caus...    -8.539  104.341   1.0   \n",
       "2  know, like, come, go, one, never, make, say, n...    -9.637  126.003   0.0   \n",
       "3  time, come, go, one, see, want, day, away, nee...   -10.969  197.625   1.0   \n",
       "4  go, see, back, wo, face, end, place, far, onc,...    -5.369  170.008   1.0   \n",
       "5  know, like, time, come, go, see, got, never, f...   -16.516  142.254   1.0   \n",
       "\n",
       "    duration     vect_1     vect_2     vect_3  ...  key_2.0  key_3.0  key_4.0  \\\n",
       "0  298.73587  44.462048 -13.499814  26.257028  ...    False    False    False   \n",
       "2  412.94322  40.376622  27.546188 -24.231226  ...    False    False    False   \n",
       "3   64.78322  45.598532  10.249509  52.666606  ...     True    False    False   \n",
       "4  191.97342  47.159148 -52.070941  18.232822  ...    False    False    False   \n",
       "5  146.75546  36.712606  -1.896533   3.454569  ...    False    False     True   \n",
       "\n",
       "   key_5.0  key_6.0  key_7.0  key_8.0  key_9.0  key_10.0  key_11.0  \n",
       "0    False    False     True    False    False     False     False  \n",
       "2    False    False    False    False    False      True     False  \n",
       "3    False    False    False    False    False     False     False  \n",
       "4    False    False    False    False    False     False     False  \n",
       "5    False    False    False    False    False     False     False  \n",
       "\n",
       "[5 rows x 173 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inputs = pd.get_dummies(df_inputs, columns=['key'], prefix='key')\n",
    "df_inputs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some Thoughts on `vect_n` features:\n",
    "\n",
    "As mentioned before, we do have 148 columns of vectors representing audio features\n",
    "extracted from each song. While this is undoubtedly useful, since it is basically\n",
    "feature engineering done from audio to vectors, this does increase our dimensionality by\n",
    "a lot. Given more time, I would probably look at the correlation between each `vect`\n",
    "feature, and observe which `vect`s are highly correlated to each other, and perhaps do\n",
    "some sort of feature engineering or feature selection to combine the effects of those\n",
    "`vect`s to reduce the dimensionality. Already with the text embeddings for `title` and\n",
    "`tags`, we might be working with over 300, close to 400 input sizes to the model. But\n",
    "for now, I'll leave it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Data Cleaning and Preprocessing\n",
    "\n",
    "This involves writing scripts to perform the cleaning and preprocessing tasks identified\n",
    "in the EDA on the dataset.\n",
    "\n",
    "As the code is all contained within the scripts `data_preparation.py`,\n",
    "`data_preprocess.py` and `torch_datasets.py` within\n",
    "`src/genrelabeller/data_preprocessing`, I will not go through the code, but I'll just\n",
    "list the steps taken:\n",
    "\n",
    "<ins>Data Preparation</ins>\n",
    "1. Takes in Raw Data\n",
    "2. Rows with null values are dropped\n",
    "3. Stop words are removed from the `title` and `tags` columns\n",
    "4. Word embeddings are retrieved for `title` and `tags`, using **Word2Vec**\n",
    "5. `time_sig` and `key` columns are one-hot-encoded\n",
    "6. Outputs a single pandas DataFrame of cleaned data \n",
    "\n",
    "<ins>Data Preprocess</ins>\n",
    "1. Takes in cleaned DataFrame from Data Preparation Output\n",
    "2. Train Test Split the dataset (Stratify on classes)\n",
    "3. One-hot-encode labels\n",
    "4. Separate the embeddings to adjust the shape later\n",
    "5. Train a Standard Scaler on the Train set, and scale both the Train and Validation Sets\n",
    "6. Drop Unique Identifiers (make sure the indexes for inputs and labels line up)\n",
    "7. Combine the features into a row-wise numpy array\n",
    "8. Convert the data into PyTorch Tensors and into PyTorch datasets and dataloaders\n",
    "9. Outputs PyTorch Dataloaders, one for Training Set and one for Validation Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Training the Model\n",
    "\n",
    "After the EDA, it was apparent that the data we're working with for this project is\n",
    "complex, given the dimensionality, as well as the fact that we're working with natural\n",
    "language text. \n",
    "\n",
    "To capture the semantics of the text data, I chose to use `Word2Vec` to convert the\n",
    "tokenised words into embeddings of 100 elements each vector. This increases the\n",
    "dimensionality of the problem by a lot, which classical models tend to struggle with. \n",
    "\n",
    "In addition, classical models like a Random Forest, which are robust\n",
    "against high dimensionality, treat each feature independently, which does not leverage\n",
    "the relationships or semantic meanings captured in the text embeddings. \n",
    "\n",
    "Therefore, a simple Feed Forward Neural Network (Multi Layer Perceptron) was chosen to\n",
    "be the model to tackle this project. Neural Networks are able to learn complex\n",
    "relationships between the features and can not only learn the relationships in the\n",
    "embeddings, but also with other features like the key or the time signature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Architecture\n",
    "![neuralnet archi](imgs/model_architecture.png)\n",
    "\n",
    "After a few runs of the training pipeline to tune the hyper parameters (MLflow was not\n",
    "used due to the lack of time to implement), I settled on the following parameters:\n",
    "* Inputs: 370\n",
    "* Hidden Neurons: 8\n",
    "* Output Neurons: 8\n",
    "* Hidden Layers: 1\n",
    "* Epochs: 200\n",
    "* Learning Rate: 0.001\n",
    "* Loss: CrossEntropy()\n",
    "\n",
    "This is actually a very small simple Neural Network. I started out with a model with\n",
    "more hidden neurosn and hidden layers, but found that the train and validation loss\n",
    "plots showed very severe overfitting. Therefore I decided to prune the model down to the\n",
    "current small architecture. **Train and Validation Losses plotted below:**\n",
    "\n",
    "![loss plots](artifacts/model/losses.png)\n",
    "\n",
    "From observation, it is obvious that we have an overfitted model as the validation loss\n",
    "diverges from the training loss very early, around epoch 10, and starts plateauing out,\n",
    "while the training loss continues to dip. \n",
    "\n",
    "There is a possibility that the train test\n",
    "split being stratified on the classes was not enough to make the validation set\n",
    "representative of the training set, and that the model is learning features that are in\n",
    "the training set that are absent in the validation set.\n",
    "\n",
    "There is also a possibility that the model is just plain overfitting to the data,\n",
    "learning noise in the training set and not being able to generalise well to the\n",
    "validation set.\n",
    "\n",
    "If time permits, we can perform error analysis on the model to gain insights as to why\n",
    "this is happening, and try to curb it and improve model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Evaluation\n",
    "Scikit-learn Classification Report:\n",
    "\n",
    "![eval metrics](imgs/model_eval.png)\n",
    "\n",
    "Given that this is an imbalanced multi-class classification problem, I have chosen to use Macro\n",
    "Averaged F1 Score as the evaluation metric to focus on.\n",
    "\n",
    "The macro averaged F1-Score is a way to represent the model's performance classifying\n",
    "across all classes as it is the average of the F1-Scores of each class. This means that\n",
    "each class contributes equally to the final score, regardless of how many samples there\n",
    "are in each class. y giving equal weight to each class, the macro-averaged F1-score\n",
    "provides a more balanced view of model performance, particularly when some classes are\n",
    "underrepresented. Such as with **\"Dance and Electronica\"** and **\"Jazz and Blues\"**.\n",
    "\n",
    "From the classification report given using Scikit-Learn's method, it is apparent that\n",
    "the model performs very poorly on songs belonging to the classes with a lower number of\n",
    "samples, like **\"Dance and Electronica\"** and **\"Jazz and Blues\"**, having a class\n",
    "F1-Score of 0.39 and 0.27 respectively. On the other hand, the model does well on the\n",
    "songs that belong to classes with a higher representation like **\"Pop\"**, **\"Metal\"**\n",
    "and **\"Punk\"**. This is quite a typical finding, as it is probably because the model\n",
    "was not trained on enough samples that were part of the lower represented classes to\n",
    "learn how to classify them well.\n",
    "\n",
    "Interestingly, the model doesn't perform very well on the highest represented classes as\n",
    "well like **\"Classic Pop and Rock\"** and **\"Folk\"**. Just through pure speculation, it\n",
    "is possible that the samples from these genres might be a little similar to other genres\n",
    "and maybe that's why the model is not classifying these well. For example, songs in\n",
    "**\"Classic Pop and Rock\"** might be similar to those in **\"Pop\"**. However, this is just\n",
    "speculation and further error analysis would have to be done to confirm this theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trained Model Saved in `artifacts/model`, Inference Output `prediction.csv` saved in `data`\n",
    "\n",
    "Model training was run and the trained model weights are saved in `artifacts/model`,\n",
    "along with the loss plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Deploying the Model Using FastAPI\n",
    "\n",
    "The app is designed to carry out a full inference pipeline given an input `.csv` file\n",
    "when the `/predict/` end point is called. Additionally, a `/genre/` and a\n",
    "`/titles/{genre}` endpoint are available which returns the unique genres in the test\n",
    "file and the titles in predicted to be in each genre respectively.\n",
    "\n",
    "Prior to writing the `app.py` script, which is run when starting the FastAPI server, I\n",
    "also wrote an `inference_pipeline.py` to get a sense of the needs and the orchestration\n",
    "of the inference pipeline. Since this part is mostly running the docker container and\n",
    "interacting with the API, I will just go through reading the SQLite database that is the output\n",
    "of the `/predict/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>trackID</th>\n",
       "      <th>title</th>\n",
       "      <th>predicted_genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6732</td>\n",
       "      <td>You Get What You Give</td>\n",
       "      <td>Classic Pop and Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>5415</td>\n",
       "      <td>Greedee</td>\n",
       "      <td>Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7757</td>\n",
       "      <td>Wonderful World</td>\n",
       "      <td>Dance and Electronica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1854</td>\n",
       "      <td>Michoacan</td>\n",
       "      <td>Classic Pop and Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>4942</td>\n",
       "      <td>HUSTLER</td>\n",
       "      <td>Soul and Reggae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>424</td>\n",
       "      <td>186</td>\n",
       "      <td>Hablame De Frente</td>\n",
       "      <td>Folk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>425</td>\n",
       "      <td>4758</td>\n",
       "      <td>Jody And The Kid</td>\n",
       "      <td>Classic Pop and Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>426</td>\n",
       "      <td>2231</td>\n",
       "      <td>Tama</td>\n",
       "      <td>Dance and Electronica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>427</td>\n",
       "      <td>2925</td>\n",
       "      <td>Billy Dee</td>\n",
       "      <td>Jazz and Blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>428</td>\n",
       "      <td>2075</td>\n",
       "      <td>Guitarra Mia</td>\n",
       "      <td>Jazz and Blues</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>428 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id trackID                  title        predicted_genre\n",
       "0      1    6732  You Get What You Give   Classic Pop and Rock\n",
       "1      2    5415                Greedee                  Metal\n",
       "2      3    7757        Wonderful World  Dance and Electronica\n",
       "3      4    1854              Michoacan   Classic Pop and Rock\n",
       "4      5    4942                HUSTLER        Soul and Reggae\n",
       "..   ...     ...                    ...                    ...\n",
       "423  424     186      Hablame De Frente                   Folk\n",
       "424  425    4758       Jody And The Kid   Classic Pop and Rock\n",
       "425  426    2231                   Tama  Dance and Electronica\n",
       "426  427    2925              Billy Dee         Jazz and Blues\n",
       "427  428    2075           Guitarra Mia         Jazz and Blues\n",
       "\n",
       "[428 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "conn = sqlite3.connect('artifacts/inference_results.db')\n",
    "query = \"SELECT * FROM inference_results\"\n",
    "df = pd.read_sql_query(query, conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside from this, I have also run an inference pipeline run and outputted a\n",
    "`predictions.csv` in the `data` folder, with only the `trackID` and `genre`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbs_assignment",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
